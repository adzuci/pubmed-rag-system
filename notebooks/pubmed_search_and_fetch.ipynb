{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# PubMed Search + Fetch (Dementia Caregiving)\n",
    "\n",
    "Set your email and optional NCBI API key as environment variables before running.\n",
    "\n",
    "To create an API key, sign in at https://account.ncbi.nlm.nih.gov/settings/ and generate an access key.\n",
    "\n",
    "Example env var setup:\n",
    "- `export NCBI_EMAIL=\"you@example.com\"` (bash/zsh)\n",
    "- `export NCBI_API_KEY=\"YOUR_KEY\"` (bash/zsh)\n",
    "- `export S3_BUCKET=\"your-bucket\"` (bash/zsh)\n",
    "\n",
    "Optional: create a local `.env` (gitignored) and load it with `python-dotenv`.\n",
    "\n",
    "Reference: https://biopython.org/docs/latest/Tutorial/chapter_entrez.html#esearch-searching-the-entrez-databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from Bio import Entrez\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "EMAIL = os.getenv(\"NCBI_EMAIL\")\n",
    "API_KEY = os.getenv(\"NCBI_API_KEY\", \"\")\n",
    "\n",
    "if not EMAIL:\n",
    "    raise ValueError(\"NCBI_EMAIL must be set in your environment or .env\")\n",
    "\n",
    "Entrez.email = EMAIL\n",
    "if API_KEY:\n",
    "    Entrez.api_key = API_KEY\n",
    "\n",
    "# Using MeSH (Medical Subject Headings) for broader recall, plus tiab\n",
    "# (Title/Abstract) terms to keep results focused and more current.\n",
    "QUERY = (\n",
    "    '(\"Dementia\"[Mesh] OR \"Mild Cognitive Impairment\"[Mesh]) '\n",
    "    'AND (\"Decision Support Systems, Clinical\"[Mesh] OR \"Caregivers\"[Mesh] '\n",
    "    'OR caregiver*[tiab] OR \"decision support\"[tiab])'\n",
    ")\n",
    "RETMAX = 500\n",
    "\n",
    "# Using usehistory to enable lazy fetches (WebEnv + QueryKey).\n",
    "# Docs: https://biopython.org/docs/latest/Tutorial/chapter_entrez.html#esearch-searching-the-entrez-databases\n",
    "try:\n",
    "    stream = Entrez.esearch(db=\"pubmed\", term=QUERY, retmax=RETMAX, usehistory=\"y\")\n",
    "    record = Entrez.read(stream)\n",
    "    stream.close()\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(f\"PubMed search failed: {exc}\")\n",
    "\n",
    "summary = {\n",
    "    \"count\": int(record.get(\"Count\", 0)),\n",
    "    \"retmax\": int(record.get(\"RetMax\", 0)),\n",
    "    \"returned_ids\": len(record.get(\"IdList\", [])),\n",
    "    \"query_translation\": record.get(\"QueryTranslation\"),\n",
    "    \"webenv\": record.get(\"WebEnv\"),\n",
    "    \"query_key\": record.get(\"QueryKey\"),\n",
    "}\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy fetch: stream up to RETMAX records using the search history, in chunks.\n",
    "import os\n",
    "import time\n",
    "\n",
    "from Bio import Medline\n",
    "\n",
    "FETCH_DIR = \"data/pubmed_fetch\"\n",
    "os.makedirs(FETCH_DIR, exist_ok=True)\n",
    "\n",
    "webenv = record.get(\"WebEnv\")\n",
    "query_key = record.get(\"QueryKey\")\n",
    "\n",
    "total_count = int(record.get(\"Count\", 0))\n",
    "target_count = min(RETMAX, total_count)\n",
    "\n",
    "batch_size = 100\n",
    "request_delay = 0.10 if API_KEY else 0.34\n",
    "\n",
    "def iter_fetch_batches():\n",
    "    if not (webenv and query_key):\n",
    "        return\n",
    "    for start in range(0, target_count, batch_size):\n",
    "        stream = Entrez.efetch(\n",
    "            db=\"pubmed\",\n",
    "            rettype=\"medline\",\n",
    "            retmode=\"text\",\n",
    "            retstart=start,\n",
    "            retmax=min(batch_size, target_count - start),\n",
    "            webenv=webenv,\n",
    "            query_key=query_key,\n",
    "        )\n",
    "        try:\n",
    "            yield stream\n",
    "        finally:\n",
    "            stream.close()\n",
    "        if start + batch_size < target_count:\n",
    "            time.sleep(request_delay)\n",
    "\n",
    "def format_record(rec):\n",
    "    parts = []\n",
    "    if rec.get(\"PMID\"):\n",
    "        parts.append(f\"PMID: {rec['PMID']}\")\n",
    "    if rec.get(\"TI\"):\n",
    "        parts.append(f\"Title: {rec['TI']}\")\n",
    "    if rec.get(\"AU\"):\n",
    "        parts.append(f\"Authors: {', '.join(rec['AU'])}\")\n",
    "    if rec.get(\"JT\"):\n",
    "        parts.append(f\"Journal: {rec['JT']}\")\n",
    "    if rec.get(\"DP\"):\n",
    "        parts.append(f\"Date: {rec['DP']}\")\n",
    "    if rec.get(\"AB\"):\n",
    "        parts.append(f\"Abstract:\\n{rec['AB']}\")\n",
    "    return \"\\n\".join(parts).strip()\n",
    "\n",
    "written = 0\n",
    "for stream in iter_fetch_batches() or []:\n",
    "    for rec in Medline.parse(stream):\n",
    "        pmid = rec.get(\"PMID\")\n",
    "        if not pmid:\n",
    "            continue\n",
    "        text = format_record(rec)\n",
    "        if not text:\n",
    "            continue\n",
    "        out_path = os.path.join(FETCH_DIR, f\"{pmid}.txt\")\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as handle:\n",
    "            handle.write(text)\n",
    "        written += 1\n",
    "\n",
    "f\"Wrote {written} records to {FETCH_DIR}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: delete fetched files.\n",
    "import shutil\n",
    "\n",
    "if os.path.isdir(FETCH_DIR):\n",
    "    shutil.rmtree(FETCH_DIR)\n",
    "    \"Deleted fetched data folder.\"\n",
    "else:\n",
    "    \"Nothing to delete.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload fetched files to the raw prefix in S3.\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "\n",
    "S3_BUCKET = os.getenv(\"S3_BUCKET\")\n",
    "RAW_PREFIX = \"raw\"\n",
    "\n",
    "if not S3_BUCKET:\n",
    "    raise ValueError(\"S3_BUCKET must be set in your environment or .env\")\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "uploaded = 0\n",
    "for filename in os.listdir(FETCH_DIR):\n",
    "    if not filename.endswith(\".txt\"):\n",
    "        continue\n",
    "    local_path = os.path.join(FETCH_DIR, filename)\n",
    "    key = f\"{RAW_PREFIX}/{filename}\"\n",
    "    s3.upload_file(local_path, S3_BUCKET, key)\n",
    "    uploaded += 1\n",
    "\n",
    "f\"Uploaded {uploaded} files to s3://{S3_BUCKET}/{RAW_PREFIX}/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubmed-rag-system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
